{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Regressions and The Naive Regression-Weighted Causal Effect"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider the following Data Generating Process:\n",
    "$$\n",
    "x = \\text{Uniform}(\\{1,2,3,4\\}) \\\\\n",
    "T = \\exp(x) + u, \\quad u \\sim N(0,\\sigma^2) \\\\ \n",
    "Y = \\sin(T) + x + v, \\quad v \\sim N(0,1) \\\\ \n",
    "$$\n",
    "\n",
    "Notice that we have $T|x \\sim N(\\exp(x),\\sigma^2)$ for each $x$. We can then calculate the conditional Yitzhaki's weights. Starting with the numerator, we have:\n",
    "$$\n",
    "E[T - E[T|x] \\mid T > t, x] \\cdot p(X > t \\mid x) = [\\exp(x) + \\sigma \\frac{\\phi(t)}{1 - \\Phi(t)} - \\exp(x)] \\cdot (1 - \\Phi(t)) = \\sigma \\phi(t) \\\\\n",
    "$$\n",
    "\n",
    "Similarly, as the variance is fixed across $x$, we have that $E[\\text{var}(T|x)] = \\sigma^2$. Therefore, the weights are:\n",
    "$$\n",
    "w(t,x) = \\frac{\\sigma \\phi(t)}{\\sigma^2} = \\frac{\\phi(t)}{\\sigma},\n",
    "$$\n",
    "which is the density of the normal distribution. Using the fact that $\\frac{\\partial \\sin(t)}{\\partial t} = \\cos(t)$, we can simply estimate the NRWCE as:\n",
    "$$\n",
    "E[\\cos(T)] \\approx \\frac{1}{n} \\sum_{i=1}^n \\cos(T_i).\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In what follows we generate Data and comapre the regressions coefficient $\\beta$ in the following regression\n",
    "$$\n",
    "Y = \\alpha + \\beta T + \\gamma x + \\epsilon\n",
    "$$\n",
    "to the $NRwCE$ estimand. In the analysis we fix $\\sigma=1$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.formula.api import ols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First block\n",
    "df1 = pd.DataFrame({'x': np.repeat(np.arange(2, 6),1000000,axis=0)})\n",
    "df1['T'] = np.exp(df1['x']) + np.random.normal(size=len(df1))\n",
    "df1['sinT'] = np.sin(df1['T'])\n",
    "df1['y'] = df1['sinT'] + df1['x'] + np.random.normal(size=len(df1))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without knowin the underlying DGP one may consider estimating the following linear model \n",
    "$$\n",
    "Y = \\alpha + \\beta T + \\gamma x + \\epsilon\n",
    "$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.255\n",
      "Model:                            OLS   Adj. R-squared:                  0.255\n",
      "Method:                 Least Squares   F-statistic:                 6.860e+05\n",
      "Date:                Thu, 25 May 2023   Prob (F-statistic):               0.00\n",
      "Time:                        21:05:39   Log-Likelihood:            -6.2420e+06\n",
      "No. Observations:             4000000   AIC:                         1.248e+07\n",
      "Df Residuals:                 3999997   BIC:                         1.248e+07\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.8376      0.003    537.237      0.000       1.831       1.844\n",
      "T              0.0039   2.78e-05    140.640      0.000       0.004       0.004\n",
      "x              0.4203      0.001    306.400      0.000       0.418       0.423\n",
      "==============================================================================\n",
      "Omnibus:                      203.381   Durbin-Watson:                   1.896\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              199.584\n",
      "Skew:                           0.010   Prob(JB):                     4.58e-44\n",
      "Kurtosis:                       2.972   Cond. No.                         509.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "result1 = ols('y ~ T + x', df1).fit()\n",
    "print(result1.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we know the DGP, we can estimate the true native regression-weighted causal effect here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated NRwCE is:  -0.04811411819821981\n"
     ]
    }
   ],
   "source": [
    "df1['dT'] = np.cos(df1['T'])\n",
    "print(\"The estimated NRwCE is: \" ,df1['dT'].mean())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, as we can see, it's different and has a different sign from our regression coefficient.\n",
    "\n",
    "Next, we can demonstrate the impact of bias and attenuation on the resulting regression coefficient. Please note that the numbers may be close but not exact, as our analysis was conducted at the population level, whereas here we are working with a sample.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The beta coefficient:  0.003907648070431813\n",
      "The bias part:  0.0040178015467263566\n",
      "The causal part:  -0.00011015347629454367\n",
      "The attenuation:  -0.04723546437065927\n",
      "The NRwCE:  -0.04734561784695381\n"
     ]
    }
   ],
   "source": [
    "ols_tx = ols('T ~ x', df1).fit()\n",
    "\n",
    "df1['DeltaX'] = np.exp(df1['x']) - ols_tx.params['x']*df1['x'] - ols_tx.params['Intercept']\n",
    "df1['linear_res_tx'] = df1['T'] - ols_tx.params['x']*df1['x'] - ols_tx.params['Intercept']\n",
    "df1['res_tx'] = df1['T'] - np.exp(df1['x'])\n",
    "df1['residualizedT'] = df1['T'] - ols_tx.params['x']*df1['x'] - ols_tx.params['Intercept']\n",
    "\n",
    "cov_bias = df1[['y', 'DeltaX']].cov().iloc[0,1]\n",
    "cov_causal = df1[['y', 'res_tx']].cov().iloc[0,1]\n",
    "sd = df1['residualizedT'].std()\n",
    "print('The beta coefficient: ',(cov_bias + cov_causal) / (sd**2))\n",
    "print('The bias part: ',(cov_bias ) / (sd**2))\n",
    "print('The causal part: ',(cov_causal) / (sd**2))\n",
    "print('The attenuation: ',cov_causal - (cov_causal) / (sd**2))\n",
    "print('The NRwCE: ',cov_causal )\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so we can see that the causal effect was attenuated to almost zero, and most of what drives $\\beta$ is is the bias term. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, assume that \n",
    "$$\n",
    "T = x + u, u \\sim N(0,1) \\\\\n",
    "Y = sin(T)+ sin(x) + v, v \\sim N(0,1) \n",
    "$$\n",
    "and we repeat the same analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.525\n",
      "Model:                            OLS   Adj. R-squared:                  0.525\n",
      "Method:                 Least Squares   F-statistic:                 2.214e+06\n",
      "Date:                Thu, 25 May 2023   Prob (F-statistic):               0.00\n",
      "Time:                        21:05:44   Log-Likelihood:            -6.1961e+06\n",
      "No. Observations:             4000000   AIC:                         1.239e+07\n",
      "Df Residuals:                 3999997   BIC:                         1.239e+07\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      3.3897      0.002   1811.268      0.000       3.386       3.393\n",
      "T             -0.2689      0.001   -472.308      0.000      -0.270      -0.268\n",
      "x             -0.7755      0.001  -1015.115      0.000      -0.777      -0.774\n",
      "==============================================================================\n",
      "Omnibus:                     5810.149   Durbin-Watson:                   1.887\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             6001.081\n",
      "Skew:                           0.079   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.105   Cond. No.                         18.2\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# First block\n",
    "df1 = pd.DataFrame({'x': np.repeat(np.arange(2, 6),1000000,axis=0)})\n",
    "df1['T'] = df1['x'] + np.random.normal(size=len(df1))\n",
    "df1['sinT'] = np.sin(df1['T'])\n",
    "df1['y'] = df1['sinT'] + np.sin(df1['x']) + np.random.normal(size=len(df1))\n",
    "\n",
    "result1 = ols('y ~ T + x', df1).fit()\n",
    "print(result1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated NRwCE is:  -0.2691692260468451\n"
     ]
    }
   ],
   "source": [
    "df1['dT'] = np.cos(df1['T'])\n",
    "print(\"The estimated NRwCE is: \" ,df1['dT'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The beta coefficient:  -0.2689132794693612\n",
      "The bias part:  0.0001238800399784524\n",
      "The causal part:  -0.2690371595093397\n",
      "The attenuation:  -9.649816335671746e-05\n",
      "The NRwCE:  -0.2691336576726964\n"
     ]
    }
   ],
   "source": [
    "ols_tx = ols('T ~ x', df1).fit()\n",
    "\n",
    "df1['DeltaX'] = df1['x'] - ols_tx.params['x']*df1['x'] - ols_tx.params['Intercept']\n",
    "df1['linear_res_tx'] = df1['T'] - ols_tx.params['x']*df1['x'] - ols_tx.params['Intercept']\n",
    "df1['res_tx'] = df1['T'] - df1['x']\n",
    "df1['residualizedT'] = df1['T'] - ols_tx.params['x']*df1['x'] - ols_tx.params['Intercept']\n",
    "\n",
    "cov_bias = df1[['y', 'DeltaX']].cov().iloc[0,1]\n",
    "cov_causal = df1[['y', 'res_tx']].cov().iloc[0,1]\n",
    "sd = df1['residualizedT'].std()\n",
    "print('The beta coefficient: ',(cov_bias + cov_causal) / (sd**2))\n",
    "print('The bias part: ',(cov_bias ) / (sd**2))\n",
    "print('The causal part: ',(cov_causal) / (sd**2))\n",
    "print('The attenuation: ',cov_causal - (cov_causal) / (sd**2))\n",
    "print('The NRwCE: ',cov_causal )\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that the regression coefficient on variable T now provides us with the corrected causal effect, even though the effect of the control variable is not linear in the outcome equation. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yitzhaki",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
